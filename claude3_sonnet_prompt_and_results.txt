The text below contains an academic paper. Extract sentences that present factual claims, research findings, or statistics from external sources, as these require citations. Do not extract sentences that express the author's opinions, beliefs, definitions, or original ideas. 

For each sentence requiring a citation, number it on a separate line and enclose the sentence in quotes. If the sentence lacks context needed to properly evaluate and find references (such as the subject area), include that context after the sentence in square brackets.

Examples of sentences requiring citations:
"Recent studies have shown a 20% increase in global temperatures over the past decade." 
"According to the World Health Organization, malaria affects over 200 million people annually [in global health]."

Examples of sentences not requiring citations:
"In my opinion, climate change is one of the greatest challenges facing humanity."
"This paper defines 'sustainable development' as economic growth that meets present needs without compromising future generations."

Preserve the original text as closely as possible when extracting sentences requiring citations.


The last few years have seen rapid progress on long-standing, difficult problems in machine learning and artificial intelligence (AI), in areas as diverse as computer vision, video game playing, autonomous vehicles, and Go. These advances have brought excitement about the positive potential for AI to transform medicine, science, and transportation, along with concerns about the privacy, security, fairness, economic, and military implications of autonomous systems, as well as concerns about the longer-term implications of powerful AI.
The authors believe that AI technologies are likely to be overwhelmingly beneficial for humanity, but we also believe that it is worth giving serious thought to potential challenges and risks. We strongly support work on privacy, security, fairness, economics, and policy, but in this document we discuss another class of problem which we believe is also relevant to the societal impacts of AI: the problem of accidents in machine learning systems. We define accidents as unintended and harmful behavior that may emerge from machine learning systems when we specify the wrong objective function, are not careful about the learning process, or commit other machine learning-related implementation errors.
There is a large and diverse literature in the machine learning community on issues related to accidents, including robustness, risk-sensitivity, and safe exploration; we review these in detail below. However, as machine learning systems are deployed in increasingly large-scale, autonomous, open- domain situations, it is worth reflecting on the scalability of such approaches and understanding what challenges remain to reducing accident risk in modern machine learning systems. Overall, we believe there are many concrete open technical problems relating to accident prevention in machine learning systems.
There has been a great deal of public discussion around accidents. To date much of this discussion has highlighted extreme scenarios such as the risk of misspecified objective functions in superintelligent agents. However, in our opinion one need not invoke these extreme scenarios to productively discuss accidents, and in fact doing so can lead to unnecessarily speculative discussions that lack precision, as noted by some critics. We believe it is usually most productive to frame accident risk in terms of practical (though often quite general) issues with modern ML techniques. As AI capabilities advance and as AI systems take on increasingly important societal functions, we expect the fundamental challenges discussed in this paper to become increasingly important. The more successfully the AI and machine learning communities are able to anticipate and understand these fundamental technical challenges, the more successful we will ultimately be in developing increasingly useful, relevant, and important AI systems.
Our goal in this document is to highlight a few concrete safety problems that are ready for ex- perimentation today and relevant to the cutting edge of AI systems, as well as reviewing existing literature on these problems. In Section 2, we frame mitigating accident risk (often referred to as “AI safety” in public discussions) in terms of classic methods in machine learning, such as supervised classification and reinforcement learning. We explain why we feel that recent directions in machine learning, such as the trend toward deep reinforcement learning and agents acting in broader environ- ments, suggest an increasing relevance for research around accidents. In Sections 3-7, we explore five concrete problems in AI safety. Each section is accompanied by proposals for relevant experiments. Section 8 discusses related efforts, and Section 9 concludes.

Here are the sentences from the given text that present factual claims, research findings, or statistics from external sources, along with any necessary context in square brackets:

1. "The last few years have seen rapid progress on long-standing, difficult problems in machine learning and artificial intelligence (AI), in areas as diverse as computer vision, video game playing, autonomous vehicles, and Go."

2. "There is a large and diverse literature in the machine learning community on issues related to accidents, including robustness, risk-sensitivity, and safe exploration; we review these in detail below."

3. "To date much of this discussion has highlighted extreme scenarios such as the risk of misspecified objective functions in superintelligent agents."

4. "As AI capabilities advance and as AI systems take on increasingly important societal functions, we expect the fundamental challenges discussed in this paper to become increasingly important."

5. "In Section 2, we frame mitigating accident risk (often referred to as "AI safety" in public discussions) in terms of classic methods in machine learning, such as supervised classification and reinforcement learning." [In the context of discussing AI safety and accident prevention]

6. "We explain why we feel that recent directions in machine learning, such as the trend toward deep reinforcement learning and agents acting in broader environ- ments, suggest an increasing relevance for research around accidents." [In the context of discussing AI safety and accident prevention]

7. "In Sections 3-7, we explore five concrete problems in AI safety." [In the context of discussing AI safety and accident prevention]