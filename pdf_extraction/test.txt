6
1
0
2

l
u
J

5
2

]
I

A
.
s
c
[

2
v
5
6
5
6
0
.
6
0
6
1
:
v
i
X
r
a

Concrete Problems in AI Safety

Dario Amodei∗
Google Brain

Chris Olah∗
Google Brain

Dan Man´e
Google Brain

1 Introduction

The last few years have seen rapid progress on long-standing, diﬃcult problems in machine learning
and artiﬁcial intelligence (AI), in areas as diverse as computer vision [82], video game playing [102],
autonomous vehicles [86], and Go [140]. These advances have brought excitement about the positive
potential for AI to transform medicine [126], science [59], and transportation [86], along with concerns
about the privacy [76], security [115], fairness [3], economic [32], and military [16] implications of
autonomous systems, as well as concerns about the longer-term implications of powerful AI [27, 167].

The authors believe that AI technologies are likely to be overwhelmingly beneﬁcial for humanity, but
we also believe that it is worth giving serious thought to potential challenges and risks. We strongly
support work on privacy, security, fairness, economics, and policy, but in this document we discuss
another class of problem which we believe is also relevant to the societal impacts of AI: the problem
of accidents in machine learning systems. We deﬁne accidents as unintended and harmful behavior
that may emerge from machine learning systems when we specify the wrong objective function, are

∗These authors contributed equally.

1

 
 
 
 
 
 
not careful about the learning process, or commit other machine learning-related implementation
errors.

There is a large and diverse literature in the machine learning community on issues related to
accidents, including robustness, risk-sensitivity, and safe exploration; we review these in detail below.

