are an editing assistant. Your task is to transform text extracted from a PDF into clean, well-formatted ASCII text. Remove page numbers, footnotes, figures, equations, and captions. Fix interruptions in the middle of sentences to make the sentence read smoothly. Where text is formatted into columns, restore it to unbroken ASCII text lines.  Reply only with the output text.

Toolformer: Language Models Can Teach Themselves to Use Tools

Timo Schick

Jane Dwivedi-Yu Roberto Dessì† Roberta Raileanu

Maria Lomeli Luke Zettlemoyer Nicola Cancedda Thomas Scialom

Meta AI Research †Universitat Pompeu Fabra

3
2
0
2

b
e
F
9

]
L
C
.
s
c
[

1
v
1
6
7
4
0
.
2
0
3
2
:
v
i
X
r
a

Abstract

Language models (LMs) exhibit remarkable
abilities to solve new tasks from just a few
examples or textual instructions, especially at
scale. They also, paradoxically, struggle with
basic functionality, such as arithmetic or fac-
tual lookup, where much simpler and smaller
In this paper, we show that
models excel.
LMs can teach themselves to use external tools
via simple APIs and achieve the best of both
worlds. We introduce Toolformer, a model
trained to decide which APIs to call, when to
call them, what arguments to pass, and how to
best incorporate the results into future token
prediction. This is done in a self-supervised
way, requiring nothing more than a handful of
demonstrations for each API. We incorporate
a range of tools, including a calculator, a Q&A
system, a search engine, a translation system,
and a calendar. Toolformer achieves substan-
tially improved zero-shot performance across
a variety of downstream tasks, often competi-
tive with much larger models, without sacriﬁc-
ing its core language modeling abilities.

1

Introduction

Large language models achieve impressive zero-
and few-shot results on a variety of natural lan-
guage processing tasks (Brown et al., 2020; Chowd-
hery et al., 2022, i.a.) and show several emergent
capabilities (Wei et al., 2022). However, all of
these models have several inherent limitations that
can at best be partially addressed by further scal-
ing. These limitations include an inability to access
up-to-date information on recent events (Komeili
et al., 2022) and the related tendency to hallucinate
facts (Maynez et al., 2020; Ji et al., 2022), difﬁcul-
ties in understanding low-resource languages (Lin
et al., 2021), a lack of mathematical skills to per-
form precise calculations (Patel et al., 2021) and an
unawareness of the progression of time (Dhingra
et al., 2022).

Figure 1: Exemplary predictions of Toolformer. The
model autonomously decides to call different APIs
(from top to bottom: a question answering system,
a calculator, a machine translation system, and a
Wikipedia search engine) to obtain information that is
useful for completing a piece of text.

A simple way to overcome these limitations of
today’s language models is to give them the abil-
ity to use external tools such as search engines,
calculators, or calendars. However, existing ap-
proaches either rely on large amounts of human
annotations (Komeili et al., 2022; Thoppilan et al.,
2022) or limit tool use to task-speciﬁc settings only
(e.g., Gao et al., 2022; Parisi et al., 2022), hinder-
ing a more widespread adoption of tool use in LMs.
Therefore, we propose Toolformer, a model that
learns to use tools in a novel way, which fulﬁlls the
following desiderata:

• The use of tools should be learned in a
self-supervised way without requiring large
amounts of human annotations. This is impor-

The New England Journal of Medicine is a registered trademark of [QA(“Who is the publisher of The New England Journal of Medicine?”) → Massachusetts Medical Society] the MMS.Out of 1400 participants, 400 (or [Calculator(400 / 1400) → 0.29] 29%) passed the test. The name derives from “la tortuga”, the Spanish word for [MT(“tortuga”) → turtle] turtle.The Brown Act is California’s law [WikiSearch(“Brown Act”) → The Ralph M. Brown Act is an act of the California State Legislature that guarantees the public's right to attend and participate in meetings of local legislative bodies.] that requires legislative bodies, like city councils, to hold their meetings open to the public. 
 
 
 
 
 
Figure 2: Key steps in our approach, illustrated for a question answering tool: Given an input text x, we ﬁrst
sample a position i and corresponding API call candidates c1
i . We then execute these API calls and
ﬁlter out all calls which do not reduce the loss Li over the next tokens. All remaining API calls are interleaved
with the original text, resulting in a new text x∗.

i , . . . , ck

i , c2

tant not only because of the costs associated
with such annotations, but also because what
humans ﬁnd useful may be different from
what a model ﬁnds useful.

• The LM should not lose any of its generality
and should be able to decide for itself when
and how to use which tool.
In contrast to
existing approaches, this enables a much more
comprehensive use of tools that is not tied to
speciﬁc tasks.

Our approach for achieving these goals is based
on the recent idea of using large LMs with in-
context learning (Brown et al., 2020) to generate
entire datasets from scratch (Schick and Schütze,
2021b; Honovich et al., 2022; Wang et al., 2022):
Given just a handful of human-written examples
of how an API can be used, we let a LM annotate
a huge language modeling dataset with potential
API calls. We then use a self-supervised loss to
determine which of these API calls actually help
the model in predicting future tokens. Finally, we
ﬁnetune the LM itself on the API calls that it con-
siders useful. As illustrated in Figure 1, through
this simple approach, LMs can learn to control a va-
riety of tools, and to choose for themselves which
tool to use when and how.

As our approach is agnostic of the dataset be-
ing used, we can apply it to the exact same dataset
that was used to pretrain a model in the ﬁrst place.
This ensures that the model does not lose any
of its generality and language modeling abilities.
We conduct experiments on a variety of differ-
ent downstream tasks, demonstrating that after
learning to use tools, Toolformer, which is based
on a pretrained GPT-J model (Wang and Komat-
suzaki, 2021) with 6.7B parameters, achieves much
stronger zero-shot results, clearly outperforming a
much larger GPT-3 model (Brown et al., 2020) and

several other baselines on various tasks.

2 Approach

Our aim is to equip a language model M with the
ability to use different tools by means of API calls.
We require that inputs and outputs for each API
can be represented as text sequences. This allows
seamless insertion of API calls into any given text,
using special tokens to mark the start and end of
each such call.

We represent each API call as a tuple c = (ac, ic)
where ac is the name of the API and ic is the cor-
responding input. Given an API call c with a cor-
responding result r, we denote the linearized se-
quences of the API call not including and including
its result, respectively, as:

e(c) = <API> ac(ic) </API>
e(c, r) = <API> ac(ic) → r </API>

where “<API>”, “</API>” and “→” are special
tokens.1 Some examples of linearized API calls
inserted into text sequences are shown in Figure 1.
Given a dataset C = {x1, . . . , x|C|} of plain
texts, we ﬁrst convert this dataset into a dataset
C∗ augmented with API calls. This is done in three
steps, illustrated in Figure 2: First, we exploit the
in-context learning ability of M to sample a large
number of potential API calls. We then execute
these API calls and ﬁnally check whether the ob-
tained responses are helpful for predicting future
tokens; this is used as a ﬁltering criterion. After
ﬁltering, we merge API calls for different tools,
resulting in the augmented dataset C∗, and ﬁnetune

1In practice, we use the token sequences “ [”, “]” and
“->” to represent “<API>”, “</API>” and “→”, respec-
tively. This enables our approach to work without modifying
the existing LM’s vocabulary. For reasons of readability, we
still refer to them as “<API>”, “</API>” and “→” through-
out this section.

x1:i-1  = Pittsburgh is              also known as   xi:n = the Steel Cityx* = Pittsburgh is         also known as        [QA(What …?         → Steel City)]         the Steel City.ci1 = What other name is          Pittsburgh known by?ci2 = Which country is         Pittsburgh in?ri1 = Steel City ri2 = United StatesLi(ci1 → Steel City) < min(Li(ci1 → ε), Li(ε))Li(ci2 → United States) > min(Li(ci2 → ε), Li(ε))1 Sample API Calls2 Execute API Calls3 Filter API CallsLM DatasetLM Dataset with API CallsExecuting API Calls As a next step, we execute
all API calls generated by M to obtain the corre-
sponding results. How this is done depends entirely
on the API itself – for example, it can involve call-
ing another neural network, executing a Python
script or using a retrieval system to perform search
over a large corpus. The response for each API call
ci needs to be a single text sequence ri.

Filtering API Calls Let i be the position of the
API call ci in the sequence x = x1, . . . , xn, and let
ri be the response from the API. Further, given a
sequence (wi | i ∈ N) of weights, let

Li(z) = −

n
(cid:88)

j=i

wj−i · log pM (xj | z, x1:j−1)

be the weighted cross entropy loss for M over the
tokens xi, . . . , xn if the model is preﬁxed with z.
We compare two different instantiations of this loss:

L+
L−

i = Li(e(ci, ri))
i = min (Li(ε), Li(e(ci, ε)))

where ε denotes an